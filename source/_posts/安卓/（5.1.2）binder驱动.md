---
title: binder驱动
categories:
- [Android,Framework内核解析,IPC Binder机制]
---

# binder驱动
学习binder的时候，一定要牢记这张图的层级结构，这样在讲解的时候，你才能知道讲解的是哪块内容。
![image](images/binder_driver_files/binder1.png)

这块我们主要掌握四个方法：

1.  binder\_init：初始化binder驱动
2.  binder\_open：打开binder驱动
3.  binder\_mmap：设置内存映射
4.  binder\_ioctl：数据读写操作

其中 binder\_init 方法是在idle初始化的时候就会调用：

```c
// kernel/common/drivers/android/binder.c
// 设备驱动入口函数
device_initcall(binder_init);
```

其他三个方法与应用层的调用关系如下：

```c
// kernel/common/drivers/android/binder.c
const struct file_operations binder_fops = {
    ... ...
    .unlocked_ioctl = binder_ioctl,
    .mmap = binder_mmap,
    .open = binder_open,
    ... ...
};
```

其中 unlocked\_ioctl 其实就是 ioctl。所以我们应用层实际调用的是下面三个方法：
![58201170.png](images/binder_driver_files/58201170.png)
接下来我们一个个分析binder驱动的这几个方法，知道这几个方法的作用后，我们在应用层调用对应方法时就知道在干什么了。

## 1.binder\_init--驱动设备的初始化

binder\_init 主要是binder驱动的初始化，代码如下：

```c
// kernel/common/drivers/android/binder.c
static int __init binder_init(void)
{
    ... ... 
    // 初始化 binder 设备
    ret = init_binder_device(device_name);
    ... ...
}
```

接着我们来看下 init\_binder\_device 方法：

```c
static int __init init_binder_device(const char *name)
{
    ... ....
    // 为binder设备分配内存
    binder_device = kzalloc(sizeof(*binder_device), GFP_KERNEL);
    if (!binder_device)
        return -ENOMEM;
    ... ...
    // 注册 Binder 驱动
    ret = misc_register(&binder_device->miscdev);
    ... ...
    // 返回注册的驱动    
    return ret;
}
```

总结：

1.  为binder驱动分配内存
2.  注册binder驱动

## 2.binder\_open--打开binder驱动

binder\_open就是打开binder驱动，这个在进程创建的时候就会执行，进程都是由zygote创建的，这个过程我们之前已经介绍了，如果对于zygote启动流程不清楚的，可以再去看下那块的流程，这里不再重复介绍了，下来我们只分析相关的代码：
进程创建时会调用 onZygoteInit 方法去创建 ProcessState对象：

### 2-1.open的执行

```c
// frameworks/base/cmds/app_process/app_main.cpp
virtual void onZygoteInit()
{
    // 初始化 ProcessState
    sp<ProcessState> proc = ProcessState::self();
    ... ...
}



// frameworks/native/libs/binder/ProcessState.cpp
sp<ProcessState> ProcessState::self()
{
    ... ...
    // 单例模式，如果有则直接返回
    if (gProcess != nullptr) {
        return gProcess;
    }
    // 没有才创建
    gProcess = new ProcessState(kDefaultDriver);
    // 返回
    return gProcess;
}
```

ProcessState::self 这个方法主要做了两件事：

1.  通过单例模式，让每个进程只有一个 ProcessState 对象。
2.  传入了一个参数，这个参数就是 ProcessState 准备启动的驱动路径。

    const char\* kDefaultDriver = "/dev/binder";

然后我们接着看下 ProcessState 的构造方法

```c
ProcessState::ProcessState(const char *driver)
    : mDriverName(String8(driver))
    , mDriverFD(open_driver(driver))
    , ... ...
{
    ... ...
    if (mDriverFD >= 0) {
        // 调用mmap，实现内存映射，最终调用到内核的 binder_mmap 方法
        mVMStart = mmap(nullptr, BINDER_VM_SIZE, PROT_READ, MAP_PRIVATE | MAP_NORESERVE, mDriverFD, 0);
        ... ...
    }
    ... ...
}



static int open_driver(const char *driver)
{
    // 因为 Linux 一切皆文件，所以打开驱动，就跟打开一个文件一样
    // 最终调用到内核的 binder_open 方法
    int fd = open(driver, O_RDWR | O_CLOEXEC);
    ... ...
    return fd;
}
```

### 2-2.binder\_open方法

```c
// kernel/common/drivers/android/binder.c
static int binder_open(struct inode *nodp, struct file *filp)
{
    struct binder_proc *proc;
    ... ...
    // 为 binder_proc结构体 在 kernel分配内存空间
    proc = kzalloc(sizeof(*proc), GFP_KERNEL);
    ... ...
    // 初始化 pro 结构体
    INIT_LIST_HEAD(&proc->todo);
    init_waitqueue_head(&proc->freeze_wait);
    ... ...
    // 将 binder_proc与 filp关联起来，这样下次通过 filp 就能找到这个 proc了
    filp->private_data = proc;
    ... ...
    // 将 proc_node 节点添加到 binder_procs 的队列头部
    hlist_add_head(&proc->proc_node, &binder_procs);
    ... ...
}
```

binder\_open方法主要做了以下几件事：

1.  创建binder\_proc对象。
2.  把当前进程等信息保存到binder\_proc对象。（该对象管理 IPC 所需的各种信息并拥有其他结构体的根结构体）
3.  把binder\_proc对象保存到文件指针filp，这个文件指针指向的就是 /dev/binder。
4.  把binder\_proc加入到全局链表binder\_procs。

其实说到底，binder\_open就做了一件事，初始化 binder\_proc。
那么binder\_proc是什么呢？可能很多同学不清楚，binder是不是要和很多进程通信？那它怎么区分不同的进程呢？每个进程是不是有自己的不同需求，那它怎么保存呢？其实这些就是通过binder\_proc 这个结构体来保存的，所以一个 binder\_proc 结构体对应一个进程，保存这个进程的信息，例如，pid、要处理的事务。然后所有进程的 binder\_proc 又是以一个双向链表保存的。如下图：
![72865820.png](https://lingzhiwen.github.io/images/binder_driver_files/72865820.png)

## 3.binder\_mmap--映射

```c
// kernel/common/drivers/android/binder.c
static int binder_mmap(struct file *filp, struct vm_area_struct *vma)
{
    // 通过文件指针拿到对应进程的 binder_proc 结构体
    struct binder_proc *proc = filp->private_data;
    ... ... 
    return binder_alloc_mmap_handler(&proc->alloc, vma);
}



int binder_alloc_mmap_handler(struct binder_alloc *alloc,
                  struct vm_area_struct *vma)
{
    ... ...
    // 如果传入的大小大于4M，保证映射内存大小不超过 4M，此处为（1M-8K）
    alloc->buffer_size = min_t(unsigned long, vma->vm_end - vma->vm_start,
                   SZ_4M);
   ... ...
    // 将 proc中的 buffer指针指向这块虚拟内存
    alloc->buffer = (void __user *)vma->vm_start;
    // 分配物理内存
    alloc->pages = kcalloc(alloc->buffer_size / PAGE_SIZE,
                   sizeof(alloc->pages[0]),
                   GFP_KERNEL);
    ... ...
    // 如果是异步，大小为同步的一半
    alloc->free_async_space = alloc->buffer_size / 2;
    // 把用户空间的虚拟地址保存在alloc里
    // alloc 就是 binder_proc 结构体的一个成员，这样我们就可以随时拿到 vma
    binder_alloc_set_vma(alloc, vma);
    ... ...
}
```

![74579249.png](images/binder_driver_files/74579249.png)
总结：binder\_mmap 做的事情就是，拿到指向用户空间和内核空间的共享内存的指针，并将他们同时指向 同一个物理内存。
我们使用这个共享内存的时候，因为这两个指针都在 binder\_proc 结构体中，所以随时可以拿到。
又因为 指向同一个物理内存，所以内核向指针buffer中存入数据，用户从指针 vma 就可以取出相同数据。

## 4.binder\_ioctl--数据读写操作

客户端向服务端发送数据时，在用户层会执行 ioctl，对应的会执行到内核层的 binder\_ioctl。
![56256675.png](images/binder_driver_files/56256675.png)

    // kernel/common/drivers/android/binder.c
    static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)
    {
        // 有很多命令，主要需要关注下面两个
        switch (cmd) {
        // 读写操作--使用频率最高
        case BINDER_WRITE_READ:
            ret = binder_ioctl_write_read(filp, cmd, arg, thread);
            ... ...
            break;
        // 设置 servicemanager 为全局上下文，这个我们介绍servicemanager时，再具体介绍
        case BINDER_SET_CONTEXT_MGR_EXT: {
            ... ...
            break;
        }
        ... ...
    }

这里我们主要分析下 binder\_ioctl\_write\_read 方法。

### 4-1.binder\_ioctl\_write\_read

    static int binder_ioctl_write_read(struct file *filp,
                    unsigned int cmd, unsigned long arg,
                    struct binder_thread *thread)
    {
        // 将用户空间数据 ubuf 拷贝到 bwr
        if (copy_from_user(&bwr, ubuf, sizeof(bwr))) {
            ... ...
        }
       ... ...
        // 如果写入数据大于0，执行写入方法
        if (bwr.write_size > 0) {
            // 这个方法就会根据不同命令，去执行具体代码
            ret = binder_thread_write(proc, thread,
                          bwr.write_buffer,
                          bwr.write_size,
                          &bwr.write_consumed);
            ... ...
        }
        // 如果读取数据大于0，执行读取方法
        if (bwr.read_size > 0) {
            // 这个方法就会根据不同命令，去执行具体代码
            ret = binder_thread_read(proc, thread, bwr.read_buffer,
                         bwr.read_size,
                         &bwr.read_consumed,
                         filp->f_flags & O_NONBLOCK);
            ... ...
        }
        ... ...
    }

可以看出这里面主要就是调用了 binder\_thread\_write 和 binder\_thread\_read 方法。
